{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc4b7af-3ba7-48e2-925d-c7c204a4eb83",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f39b2e-2703-4375-8d54-214f265d4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd1994d-3e2f-4cb7-ad91-b0524d653a85",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     BertTokenizer,\n\u001b[0;32m      3\u001b[0m     BertForSequenceClassification,\n\u001b[0;32m      4\u001b[0m     Trainer,\n\u001b[0;32m      5\u001b[0m     TrainingArguments,\n\u001b[0;32m      6\u001b[0m     BertModel\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2276\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2276\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2277\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2278\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2306\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2304\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2306\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Optional, Union\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# ruff: isort: off\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# ruff: isort: on\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhf_hub_utils\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2276\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2276\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2277\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2278\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2306\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2304\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2306\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\integrations\\integration_utils.py:42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_MODE\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚙️  Running in WANDB offline mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel, TrainingArguments\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m     PushToHubMixin,\n\u001b[0;32m     46\u001b[0m     flatten_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     logging,\n\u001b[0;32m     52\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2276\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2276\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2277\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2278\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2306\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\import_utils.py:2304\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2306\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_gelu\u001b[39m(x):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Gaussian Error Linear Unit. Original Implementation of the gelu activation function in Google Bert repo when\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    initially created. For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) Also see\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    https://huggingface.co/papers/1606.08415\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BertModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a857196-0746-4c4d-a129-99395b10aeee",
   "metadata": {},
   "source": [
    "#### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7803e5-54ab-40fc-a65a-630e0a96cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/Dell/Desktop/XAI_Model/SpamAssasin.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/Dell/Desktop/XAI_Model/CEAS_08.csv\")\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be055ab-e2af-4809-9fa6-811d266869c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0d2c1-671f-49c2-bb50-a6782e88a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ccf6f-a46d-4dd9-abcf-c0bff6e02f06",
   "metadata": {},
   "source": [
    "#### Data cleaning/preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865c955-bcaf-4614-975c-91910a7771f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['receiver', 'subject', 'body', 'label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a93a3-7591-491f-bb07-922e281f8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568b4ba-ff32-4b38-a494-d24f1863bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['urls'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d4a99-5bf3-4ab5-a7ee-54605856793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_text_cleaning(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'(from:|to:|subject:|date:|reply-to:|message-id:).*?\\n', '', text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', ' URL_TOKEN ', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' EMAIL_TOKEN ', text)\n",
    "    text = re.sub(r'[\\+]?[1-9]?[0-9]{7,15}', ' PHONE_TOKEN ', text)\n",
    "    text = re.sub(r'[!]{3,}', ' MULTIPLE_EXCLAMATION ', text)\n",
    "    text = re.sub(r'[\\?]{3,}', ' MULTIPLE_QUESTION ', text)\n",
    "    text = re.sub(r'[$]{2,}', ' MULTIPLE_DOLLAR ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s!?$.]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcb781-02b7-4d38-beb3-4e67b5c5ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-cleaning\n",
    "df['subject_clean'] = df['subject'].apply(advanced_text_cleaning)\n",
    "df['body_clean'] = df['body'].apply(advanced_text_cleaning)\n",
    "df['text'] = df['subject_clean'] + ' ' + df['body_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86302f3c-d66d-4725-a6dc-3462881bf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label-cleaning\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772a209-fa5b-4e61-90f0-ed456eb09d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].str.len() > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e9495-5ffe-4d1b-a62d-4812e91080b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'label', 'urls']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f098e1-9c4d-4649-b9f8-ecef11d9c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b672f3a-77af-412a-936a-3ccc20c919bf",
   "metadata": {},
   "source": [
    "#### Feature engineering & scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3999540-1b2d-4ff7-a9f4-403c237a6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_features_row(text, url_count=0):\n",
    "    features = {\n",
    "        'char_count': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'sentence_count': text.count('.') + text.count('!') + text.count('?'),\n",
    "        'avg_word_length': len(text) / (len(text.split()) + 1e-5),\n",
    "        'exclamation_count': text.count('!'),\n",
    "        'question_count': text.count('?'),\n",
    "        'dollar_count': text.count('$'),\n",
    "        'capital_count': sum(1 for c in text if c.isupper()),\n",
    "        'capital_ratio': sum(1 for c in text if c.isupper()) / (len(text) + 1e-5),\n",
    "        'url_count': url_count,\n",
    "        'has_url': int(url_count > 0),\n",
    "        'has_attachment': int('attachment' in text.lower())\n",
    "    }\n",
    "    \n",
    "    # sus-words detection\n",
    "    suspicious_words = ['urgent', 'immediate', 'act now', 'limited time', 'click here', \n",
    "                       'free', 'winner', 'prize', 'verify', 'confirm', 'suspended']\n",
    "    \n",
    "    for word in suspicious_words:\n",
    "        features[f'contains_{word.replace(\" \", \"_\")}'] = int(word in text)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a65b6-bcb7-49a4-88eb-72fa6357c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dicts = [extract_email_features_row(text, url_count) \n",
    "                for text, url_count in zip(df['text'], df['urls'])]\n",
    "\n",
    "feature_df = pd.DataFrame(feature_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3b117-0956-48a8-8473-6f01762b8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of features: {len(feature_df.columns)}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Feature matrix shape: {feature_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765be80-5df2-449e-8532-94c7a8bf9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeature columns:\")\n",
    "print(feature_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b1327-585d-4859-8030-759e3ff3ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeature statistics:\")\n",
    "print(feature_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f282def-0996-4748-95ea-13da95897f0e",
   "metadata": {},
   "source": [
    "#### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0e7db-1502-4bda-9c72-ba56b56d4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ecb15-3250-4cfe-beda-9043504433ef",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202813d5-6b98-4bfb-b057-9457987d790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = df['text'].tolist()\n",
    "X_tabular = scaled_features\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf2f4b-4b65-47b2-8412-d9767df0d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, X_tab_train, X_tab_test, y_train, y_test = train_test_split(\n",
    "    X_text, X_tabular, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab4085-4fe6-4f3b-a8ba-2d369edf63a8",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a8168-6803-4288-ba9e-a76a3af50f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde80d50-37c0-4a91-9b99-63735d09a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_texts(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e2935-563f-4ce4-b1fd-e7338b0a7dc5",
   "metadata": {},
   "source": [
    "#### PYTORCH DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e0ebf-5848-4291-a4d0-28f041ef1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, texts, tabular_features, labels):\n",
    "        self.encodings = tokenize_texts(texts)\n",
    "        self.tabular = torch.tensor(tabular_features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['tabular'] = self.tabular[idx]\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad4bb2-b9c1-4bd2-b4c6-f0ec1d3075c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HybridDataset(X_text_train, X_tab_train, y_train)\n",
    "test_dataset = HybridDataset(X_text_test, X_tab_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d95ff7-c4f1-4eab-9095-3bba1bd01aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2163b3-9652-4851-bc4b-1acae279d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fd097-ebc0-4b17-b20a-81b93478d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9a7f1-a194-4039-95fa-9d4a76c11b5e",
   "metadata": {},
   "source": [
    "#### Hybrid Model (BERT + Tabular Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63167943-83b7-4b6e-9f80-12d77b1d2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTWithTabular(nn.Module):\n",
    "    def __init__(self, tabular_dim):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.tabular_fc = nn.Linear(tabular_dim, 64)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + 64, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, tabular, **kwargs):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        tab_feats = torch.relu(self.tabular_fc(tabular))\n",
    "        fused = torch.cat((pooled_output, tab_feats), dim=1)\n",
    "        fused = self.dropout(fused)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4fa08-cad9-4989-b55e-f101c897d714",
   "metadata": {},
   "source": [
    "#### training and model SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efeaf25-30ea-4080-b24d-921d6079d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd484872-a901-4afc-b335-9e604e4a400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57b176-1433-4a3c-96ba-262c5487aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTWithTabular(tabular_dim=X_tabular.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746a205-3643-44ec-b28c-bfd88207462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc80434-8d96-4f75-9b17-be7940dcb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cee005-2067-41a4-b126-6d299bab1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f355f-66f7-46a0-ab6c-c40ab9beee71",
   "metadata": {},
   "source": [
    "#### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee1149-871a-4200-88f3-9bcb7ae3a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_accuracies = [], [], []\n",
    "best_val_loss = float('inf')\n",
    "patience, counter = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c535d86-f472-40cb-b6fd-0afa06e4e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader, start=1):\n",
    "        print(f\"[Train] Step {step}/{len(train_loader)}\")\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        tabular = batch['tabular'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, tabular)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6764ff-59c9-468b-bb62-cecc71d7f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(test_loader, start=1):\n",
    "            print(f\"[Eval] Step {step}/{len(test_loader)}\")\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            tabular = batch['tabular'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, tabular)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    return avg_loss, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f743ce-bac3-47c2-8daa-6f25dab294c7",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a44bc9-2011-4664-b2dc-a84d18c595cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 3\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "counter = 0\n",
    "\n",
    "print(\"-\" * 100)\n",
    "print(f\"Device: {device}\")\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f910e-cac8-4e6b-acf1-69609a095f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    # eval on validation set\n",
    "    val_loss, val_preds, val_labels = evaluate(model, test_loader, loss_fn, device)\n",
    "    \n",
    "    # validation accuracy\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    \n",
    "    # metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # epoch results\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # early-stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc\n",
    "        }, \"best_model.pt\")\n",
    "        print(f\"  New best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"  No improvement ({counter}/{patience})\")\n",
    "        \n",
    "        if counter >= patience:\n",
    "            print(\"  Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86ce7d-36fc-41ba-abb4-e528f276c1b7",
   "metadata": {},
   "source": [
    "#### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844bde4-21ac-4160-908b-1392ac4bf49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading best model for final evaluation\n",
    "checkpoint = torch.load(\"best_model.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Best model from epoch {checkpoint['epoch'] + 1} loaded (Val Loss: {checkpoint['val_loss']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51874c-a467-4def-bb97-54c948329d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "all_probas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46769d37-ef30-4b33-ab16-b99598eb7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        tabular = batch['tabular'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        logits = model(input_ids, attention_mask, tabular)\n",
    "        \n",
    "        # Get predictions and probabilities\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        probas = torch.softmax(logits, dim=1)[:, 1]  # Probability of positive class\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probas.extend(probas.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b03969e-ca37-48cb-8b48-df6b76dbabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# final metrics\n",
    "final_accuracy = accuracy_score(all_labels, all_preds)\n",
    "final_f1 = f1_score(all_labels, all_preds)\n",
    "final_auc = roc_auc_score(all_labels, all_probas)\n",
    "\n",
    "print(f\"final Accuracy = {final_accuracy:.4f}\")\n",
    "print(f\"final F1 Score = {final_f1:.4f}\")\n",
    "print(f\"final AUC-ROC = {final_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d670ee-5d66-40cb-8dfd-6938caccda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Ham', 'Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b77359-1c27-4727-b651-e79f8ff70eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Ham', 'Spam'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b0cb7-1501-489f-9e20-8eaffc772f20",
   "metadata": {},
   "source": [
    "#### Training/Validation Loss, Accuracy plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513bf83b-c92a-4dd5-81ee-11dbb79b4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "#1: train&val Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "#2: val Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, 'g-', label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "#3: train-val Loss \n",
    "plt.subplot(1, 3, 3)\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "plt.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "plt.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "plt.fill_between(epochs, train_losses, val_losses, alpha=0.2, color='gray')\n",
    "plt.title('Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e292e68-9b63-4b3a-bad3-008bff4a2310",
   "metadata": {},
   "source": [
    "#### TRAINING SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79da388-19ff-4bcf-a5be-f807a89c2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"epochs completed = {len(train_losses)}\")\n",
    "print(f\"best validation loss = {best_val_loss:.4f}\")\n",
    "print(f\"best validation accuracy = {max(val_accuracies):.4f}\")\n",
    "print(f\"final training loss = {train_losses[-1]:.4f}\")\n",
    "print(f\"final validation loss = {val_losses[-1]:.4f}\")\n",
    "print(f\"final validation accuracy = {val_accuracies[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e339e-a793-46ac-ae39-7687e497615b",
   "metadata": {},
   "source": [
    "#### SHAP INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a8b47-69d6-4739-a228-b5dc7a592f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import shap\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from shap.maskers import Text\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267e749-4dc0-4b97-b9ee-ded412a06ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== cleaning ==========\n",
    "def advanced_text_cleaning(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'(from:|to:|subject:|date:|reply-to:|message-id:).*?\\n', '', text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', ' URL_TOKEN ', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' EMAIL_TOKEN ', text)\n",
    "    text = re.sub(r'[\\+]?[1-9]?[0-9]{7,15}', ' PHONE_TOKEN ', text)\n",
    "    text = re.sub(r'[!]{3,}', ' MULTIPLE_EXCLAMATION ', text)\n",
    "    text = re.sub(r'[\\?]{3,}', ' MULTIPLE_QUESTION ', text)\n",
    "    text = re.sub(r'[$]{2,}', ' MULTIPLE_DOLLAR ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s!?$.]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# ========== Feature Engineering ==========\n",
    "def extract_email_features_row(text, url_count=0):\n",
    "    features = {\n",
    "        'char_count': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'sentence_count': text.count('.') + text.count('!') + text.count('?'),\n",
    "        'avg_word_length': len(text) / (len(text.split()) + 1e-5),\n",
    "        'exclamation_count': text.count('!'),\n",
    "        'question_count': text.count('?'),\n",
    "        'dollar_count': text.count('$'),\n",
    "        'capital_count': sum(1 for c in text if c.isupper()),\n",
    "        'capital_ratio': sum(1 for c in text if c.isupper()) / (len(text) + 1e-5),\n",
    "        'url_count': url_count,\n",
    "        'has_url': int(url_count > 0),\n",
    "        'has_attachment': int('attachment' in text.lower())\n",
    "    }\n",
    "    suspicious_words = ['urgent', 'immediate', 'act now', 'limited time', 'click here',\n",
    "                        'free', 'winner', 'prize', 'verify', 'confirm', 'suspended']\n",
    "    for word in suspicious_words:\n",
    "        features[f'contains_{word.replace(\" \", \"_\")}'] = int(word in text)\n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d7feb-a36c-433c-a3ba-ea803dcb41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Model (Only forward compatible for SHAP) ==========\n",
    "class BERTWithTabular(torch.nn.Module):\n",
    "    def __init__(self, tabular_dim):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.tabular_fc = torch.nn.Linear(tabular_dim, 64)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size + 64, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, tabular):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        tab_feats = torch.relu(self.tabular_fc(tabular))\n",
    "        fused = torch.cat((pooled_output, tab_feats), dim=1)\n",
    "        fused = self.dropout(fused)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f24af-f0f4-4c55-b50c-91b5b17de30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== loding Trained Model ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTWithTabular(tabular_dim=23).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1469f08-1b1e-42fe-91cd-75263d157ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"best_model.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1d769-f5b4-4c31-a748-49691b158b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SHAP Prediction Wrapper ==========\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "max_len = 256\n",
    "\n",
    "def predict_shap_raw(texts):\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    enc = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_len).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.bert(**enc).pooler_output\n",
    "    return output.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b6ba9-f12b-42a9-939d-f79248e62f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Inference Pipeline ==========\n",
    "def run_shap_inference(row, scaler, return_shap=True):\n",
    "    subject_clean = advanced_text_cleaning(row['subject'])\n",
    "    body_clean = advanced_text_cleaning(row['body'])\n",
    "    full_text = subject_clean + \" \" + body_clean\n",
    "    print(f\"[DEBUG] Text length: {len(full_text)}\")\n",
    "    print(f\"[DEBUG] Text preview: {full_text[:300]}\")\n",
    "    \n",
    "    # Tabular features\n",
    "    features_df = extract_email_features_row(full_text, row.get(\"urls\", 0))\n",
    "    tabular_tensor = torch.tensor(scaler.transform(features_df), dtype=torch.float32).to(device)\n",
    "\n",
    "    # Tokenization\n",
    "    enc = tokenizer([full_text], padding=True, truncation=True, return_tensors=\"pt\", max_length=max_len).to(device)\n",
    "\n",
    "    # Model prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(enc['input_ids'], enc['attention_mask'], tabular_tensor)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "        predicted_class = int(np.argmax(probs))\n",
    "        confidence = probs[predicted_class]\n",
    "\n",
    "    result = {\n",
    "        \"text\": full_text,\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"confidence\": confidence,\n",
    "        \"probabilities\": probs.tolist()\n",
    "    }\n",
    "\n",
    "    # SHAP explanation\n",
    "    if return_shap:\n",
    "        text_masker = Text(tokenizer=tokenizer)\n",
    "        explainer = shap.Explainer(predict_shap_raw, masker=text_masker)\n",
    "        shap_values = explainer([full_text])  # wrap in list\n",
    "        result[\"shap_values\"] = shap_values[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547ab2a-774a-4c52-9a3e-b14153e66cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/LOQ/Desktop/SpamAssasin.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/LOQ/Desktop/CEAS_08.csv\")\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.dropna(subset=['receiver', 'subject', 'body', 'label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7e577-9bfb-4a42-bf41-25bbf3f2096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject_clean'] = df['subject'].apply(advanced_text_cleaning)\n",
    "df['body_clean'] = df['body'].apply(advanced_text_cleaning)\n",
    "df['text'] = df['subject_clean'] + ' ' + df['body_clean']\n",
    "df = df[df['text'].str.len() > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785314b-2c4b-4ae3-8f5c-fcab8edc02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit scaler on all features\n",
    "feature_df = pd.concat([extract_email_features_row(t) for t in df['text']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4e02b-0903-4dcd-960e-f9df1be54a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c23e3-dee2-41c0-8679-3a58ae1b0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= pick one sample for testing/inference =========\n",
    "sample_row = df.iloc[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fa727-ad07-4ef0-adcf-457f927d7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fb541-7ea7-4dcf-9b66-6c6f3e395900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference + SHAP\n",
    "result = run_shap_inference(sample_row, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d4c73-b8f1-4580-88a2-1a2324ff3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= print & visualize =========\n",
    "print(f\"Prediction = {'Phishing' if result['predicted_class'] == 1 else 'Legitimate'}\")\n",
    "print(f\"Confidence = {result['confidence']:.3f}\")\n",
    "print(f\"Probabilities = {result['probabilities']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf9bae-a442-48f4-9782-8292dc7ad7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP-visualization\n",
    "shap.plots.text(result['shap_values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d17d8-31ae-4846-919c-fe2ff7683ba6",
   "metadata": {},
   "source": [
    "#### LIME INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d654ab-a98b-45cc-967a-d0f1ddfffaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0d8bb-c6e0-40d3-ae2f-ba75b817587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lime_inference(row, scaler, num_features=10):\n",
    "    subject_clean = advanced_text_cleaning(row['subject'])\n",
    "    body_clean = advanced_text_cleaning(row['body'])\n",
    "    full_text = subject_clean + \" \" + body_clean\n",
    "    base_features_df = extract_email_features_row(full_text, row.get(\"urls\", 0))\n",
    "    base_features_scaled = scaler.transform(base_features_df)\n",
    "    tabular_tensor_base = torch.tensor(base_features_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Define LIME prediction wrapper\n",
    "    def lime_predict(texts):\n",
    "        results = []\n",
    "        for txt in texts:\n",
    "            # Clean and extract tabular features for each LIME-perturbed sample\n",
    "            features_df = extract_email_features_row(txt)\n",
    "            features_scaled = scaler.transform(features_df)\n",
    "            tabular_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "            # Tokenize\n",
    "            enc = tokenizer([txt], padding=True, truncation=True, return_tensors=\"pt\", max_length=max_len).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(enc['input_ids'], enc['attention_mask'], tabular_tensor)\n",
    "                probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "                results.append(probs)\n",
    "\n",
    "        return np.array(results)\n",
    "\n",
    "    # explainer\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    explanation = explainer.explain_instance(full_text, lime_predict, num_features=num_features)\n",
    "\n",
    "    # prediction\n",
    "    pred_probs = lime_predict([full_text])[0]\n",
    "    predicted_class = int(np.argmax(pred_probs))\n",
    "    confidence = pred_probs[predicted_class]\n",
    "\n",
    "    result = {\n",
    "        \"text\": full_text,\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"confidence\": confidence,\n",
    "        \"probabilities\": pred_probs.tolist(),\n",
    "        \"lime_explanation\": explanation\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22c4c4-e1d9-4e12-854e-12f82e1abcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = df.iloc[20000]\n",
    "result_lime = run_lime_inference(sample_row, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d07ac-047b-4520-9dfd-fa8bbee0bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lime['lime_explanation'].show_in_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
