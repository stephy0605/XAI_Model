{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc4b7af-3ba7-48e2-925d-c7c204a4eb83",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f39b2e-2703-4375-8d54-214f265d4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd1994d-3e2f-4cb7-ad91-b0524d653a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "   \n",
    "    BertModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a857196-0746-4c4d-a129-99395b10aeee",
   "metadata": {},
   "source": [
    "#### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7803e5-54ab-40fc-a65a-630e0a96cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/Dell/Desktop/XAI_Model/SpamAssasin.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/Dell/Desktop/XAI_Model/CEAS_08.csv\")\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be055ab-e2af-4809-9fa6-811d266869c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Elz &lt;kre@munnari.OZ.AU&gt;</td>\n",
       "      <td>Chris Garrigues &lt;cwg-dated-1030377287.06fa6d@D...</td>\n",
       "      <td>Thu, 22 Aug 2002 18:26:25 +0700</td>\n",
       "      <td>Re: New Sequences Window</td>\n",
       "      <td>Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steve Burt &lt;Steve_Burt@cursor-system.com&gt;</td>\n",
       "      <td>\"'zzzzteana@yahoogroups.com'\" &lt;zzzzteana@yahoo...</td>\n",
       "      <td>Thu, 22 Aug 2002 12:46:18 +0100</td>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>Martin A posted:\\nTassos Papadopoulos, the Gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Tim Chapman\" &lt;timc@2ubh.com&gt;</td>\n",
       "      <td>zzzzteana &lt;zzzzteana@yahoogroups.com&gt;</td>\n",
       "      <td>Thu, 22 Aug 2002 13:52:38 +0100</td>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>Man Threatens Explosion In Moscow \\n\\nThursday...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monty Solomon &lt;monty@roscom.com&gt;</td>\n",
       "      <td>undisclosed-recipient: ;</td>\n",
       "      <td>Thu, 22 Aug 2002 09:15:25 -0400</td>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die</td>\n",
       "      <td>Klez: The Virus That Won't Die\\n \\nAlready the...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stewart Smith &lt;Stewart.Smith@ee.ed.ac.uk&gt;</td>\n",
       "      <td>zzzzteana@yahoogroups.com</td>\n",
       "      <td>Thu, 22 Aug 2002 14:38:22 +0100</td>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make</td>\n",
       "      <td>&gt;  in adding cream to spaghetti carbonara, whi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sender  \\\n",
       "0             Robert Elz <kre@munnari.OZ.AU>   \n",
       "1  Steve Burt <Steve_Burt@cursor-system.com>   \n",
       "2              \"Tim Chapman\" <timc@2ubh.com>   \n",
       "3           Monty Solomon <monty@roscom.com>   \n",
       "4  Stewart Smith <Stewart.Smith@ee.ed.ac.uk>   \n",
       "\n",
       "                                            receiver  \\\n",
       "0  Chris Garrigues <cwg-dated-1030377287.06fa6d@D...   \n",
       "1  \"'zzzzteana@yahoogroups.com'\" <zzzzteana@yahoo...   \n",
       "2              zzzzteana <zzzzteana@yahoogroups.com>   \n",
       "3                           undisclosed-recipient: ;   \n",
       "4                          zzzzteana@yahoogroups.com   \n",
       "\n",
       "                              date  \\\n",
       "0  Thu, 22 Aug 2002 18:26:25 +0700   \n",
       "1  Thu, 22 Aug 2002 12:46:18 +0100   \n",
       "2  Thu, 22 Aug 2002 13:52:38 +0100   \n",
       "3  Thu, 22 Aug 2002 09:15:25 -0400   \n",
       "4  Thu, 22 Aug 2002 14:38:22 +0100   \n",
       "\n",
       "                                          subject  \\\n",
       "0                        Re: New Sequences Window   \n",
       "1                       [zzzzteana] RE: Alexander   \n",
       "2                       [zzzzteana] Moscow bomber   \n",
       "3           [IRR] Klez: The Virus That  Won't Die   \n",
       "4  Re: [zzzzteana] Nothing like mama used to make   \n",
       "\n",
       "                                                body  label  urls  \n",
       "0  Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...      0     1  \n",
       "1  Martin A posted:\\nTassos Papadopoulos, the Gre...      0     1  \n",
       "2  Man Threatens Explosion In Moscow \\n\\nThursday...      0     1  \n",
       "3  Klez: The Virus That Won't Die\\n \\nAlready the...      0     1  \n",
       "4  >  in adding cream to spaghetti carbonara, whi...      0     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a0d2c1-671f-49c2-bb50-a6782e88a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44963 entries, 0 to 44962\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sender    44963 non-null  object\n",
      " 1   receiver  44291 non-null  object\n",
      " 2   date      44963 non-null  object\n",
      " 3   subject   44919 non-null  object\n",
      " 4   body      44962 non-null  object\n",
      " 5   label     44963 non-null  int64 \n",
      " 6   urls      44963 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ccf6f-a46d-4dd9-abcf-c0bff6e02f06",
   "metadata": {},
   "source": [
    "#### Data cleaning/preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8865c955-bcaf-4614-975c-91910a7771f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['receiver', 'subject', 'body', 'label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b18a93a3-7591-491f-bb07-922e281f8d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sender      0\n",
       "receiver    0\n",
       "date        0\n",
       "subject     0\n",
       "body        0\n",
       "label       0\n",
       "urls        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8568b4ba-ff32-4b38-a494-d24f1863bcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['urls'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd3d4a99-5bf3-4ab5-a7ee-54605856793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_text_cleaning(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'(from:|to:|subject:|date:|reply-to:|message-id:).*?\\n', '', text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', ' URL_TOKEN ', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' EMAIL_TOKEN ', text)\n",
    "    text = re.sub(r'[\\+]?[1-9]?[0-9]{7,15}', ' PHONE_TOKEN ', text)\n",
    "    text = re.sub(r'[!]{3,}', ' MULTIPLE_EXCLAMATION ', text)\n",
    "    text = re.sub(r'[\\?]{3,}', ' MULTIPLE_QUESTION ', text)\n",
    "    text = re.sub(r'[$]{2,}', ' MULTIPLE_DOLLAR ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s!?$.]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebcb781-02b7-4d38-beb3-4e67b5c5ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-cleaning\n",
    "df['subject_clean'] = df['subject'].apply(advanced_text_cleaning)\n",
    "df['body_clean'] = df['body'].apply(advanced_text_cleaning)\n",
    "df['text'] = df['subject_clean'] + ' ' + df['body_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86302f3c-d66d-4725-a6dc-3462881bf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label-cleaning\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e772a209-fa5b-4e61-90f0-ed456eb09d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].str.len() > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656e9495-5ffe-4d1b-a62d-4812e91080b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'label', 'urls']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f098e1-9c4d-4649-b9f8-ecef11d9c58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 44251 entries, 0 to 44962\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    44251 non-null  object\n",
      " 1   label   44251 non-null  int64 \n",
      " 2   urls    44251 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b672f3a-77af-412a-936a-3ccc20c919bf",
   "metadata": {},
   "source": [
    "#### Feature engineering & scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3999540-1b2d-4ff7-a9f4-403c237a6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_features_row(text, url_count=0):\n",
    "    features = {\n",
    "        'char_count': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'sentence_count': text.count('.') + text.count('!') + text.count('?'),\n",
    "        'avg_word_length': len(text) / (len(text.split()) + 1e-5),\n",
    "        'exclamation_count': text.count('!'),\n",
    "        'question_count': text.count('?'),\n",
    "        'dollar_count': text.count('$'),\n",
    "        'capital_count': sum(1 for c in text if c.isupper()),\n",
    "        'capital_ratio': sum(1 for c in text if c.isupper()) / (len(text) + 1e-5),\n",
    "        'url_count': url_count,\n",
    "        'has_url': int(url_count > 0),\n",
    "        'has_attachment': int('attachment' in text.lower())\n",
    "    }\n",
    "    \n",
    "    # sus-words detection\n",
    "    suspicious_words = ['urgent', 'immediate', 'act now', 'limited time', 'click here', \n",
    "                       'free', 'winner', 'prize', 'verify', 'confirm', 'suspended']\n",
    "    \n",
    "    for word in suspicious_words:\n",
    "        features[f'contains_{word.replace(\" \", \"_\")}'] = int(word in text)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d00a65b6-bcb7-49a4-88eb-72fa6357c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dicts = [extract_email_features_row(text, url_count) \n",
    "                for text, url_count in zip(df['text'], df['urls'])]\n",
    "\n",
    "feature_df = pd.DataFrame(feature_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bb3b117-0956-48a8-8473-6f01762b8131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 23\n",
      "Dataset shape: (44251, 3)\n",
      "Feature matrix shape: (44251, 23)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {len(feature_df.columns)}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Feature matrix shape: {feature_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6765be80-5df2-449e-8532-94c7a8bf9d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature columns:\n",
      "['char_count', 'word_count', 'sentence_count', 'avg_word_length', 'exclamation_count', 'question_count', 'dollar_count', 'capital_count', 'capital_ratio', 'url_count', 'has_url', 'has_attachment', 'contains_urgent', 'contains_immediate', 'contains_act_now', 'contains_limited_time', 'contains_click_here', 'contains_free', 'contains_winner', 'contains_prize', 'contains_verify', 'contains_confirm', 'contains_suspended']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature columns:\")\n",
    "print(feature_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "086b1327-585d-4859-8030-759e3ff3ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature statistics:\n",
      "          char_count    word_count  sentence_count  avg_word_length  \\\n",
      "count   44251.000000  44251.000000    44251.000000     44251.000000   \n",
      "mean     1319.883415    226.736548       18.595376         5.903886   \n",
      "std      3633.188196    543.760521       57.077018         2.085177   \n",
      "min        21.000000      2.000000        0.000000         2.414971   \n",
      "25%       252.000000     44.000000        3.000000         5.320312   \n",
      "50%       561.000000    100.000000        8.000000         5.584158   \n",
      "75%      1473.000000    262.000000       19.000000         5.999996   \n",
      "max    230437.000000  21713.000000     3359.000000        53.559313   \n",
      "\n",
      "       exclamation_count  question_count  dollar_count  capital_count  \\\n",
      "count       44251.000000    44251.000000  44251.000000   44251.000000   \n",
      "mean            1.088540        1.024813      0.631624      43.780932   \n",
      "std             5.313654        2.829572      8.222032     277.029665   \n",
      "min             0.000000        0.000000      0.000000       0.000000   \n",
      "25%             0.000000        0.000000      0.000000       8.000000   \n",
      "50%             0.000000        0.000000      0.000000       8.000000   \n",
      "75%             1.000000        1.000000      0.000000      28.000000   \n",
      "max           198.000000      121.000000   1441.000000   25136.000000   \n",
      "\n",
      "       capital_ratio     url_count  ...  contains_immediate  contains_act_now  \\\n",
      "count   44251.000000  44251.000000  ...        44251.000000      44251.000000   \n",
      "mean        0.038553      0.698425  ...            0.020836          0.001921   \n",
      "std         0.042553      0.458947  ...            0.142836          0.043786   \n",
      "min         0.000000      0.000000  ...            0.000000          0.000000   \n",
      "25%         0.002968      0.000000  ...            0.000000          0.000000   \n",
      "50%         0.026316      1.000000  ...            0.000000          0.000000   \n",
      "75%         0.054334      1.000000  ...            0.000000          0.000000   \n",
      "max         0.569659      1.000000  ...            1.000000          1.000000   \n",
      "\n",
      "       contains_limited_time  contains_click_here  contains_free  \\\n",
      "count           44251.000000          44251.00000   44251.000000   \n",
      "mean                0.002802              0.08836       0.135952   \n",
      "std                 0.052862              0.28382       0.342741   \n",
      "min                 0.000000              0.00000       0.000000   \n",
      "25%                 0.000000              0.00000       0.000000   \n",
      "50%                 0.000000              0.00000       0.000000   \n",
      "75%                 0.000000              0.00000       0.000000   \n",
      "max                 1.000000              1.00000       1.000000   \n",
      "\n",
      "       contains_winner  contains_prize  contains_verify  contains_confirm  \\\n",
      "count     44251.000000    44251.000000     44251.000000      44251.000000   \n",
      "mean          0.005220        0.003887         0.006734          0.017830   \n",
      "std           0.072063        0.062225         0.081787          0.132335   \n",
      "min           0.000000        0.000000         0.000000          0.000000   \n",
      "25%           0.000000        0.000000         0.000000          0.000000   \n",
      "50%           0.000000        0.000000         0.000000          0.000000   \n",
      "75%           0.000000        0.000000         0.000000          0.000000   \n",
      "max           1.000000        1.000000         1.000000          1.000000   \n",
      "\n",
      "       contains_suspended  \n",
      "count        44251.000000  \n",
      "mean             0.005491  \n",
      "std              0.073901  \n",
      "min              0.000000  \n",
      "25%              0.000000  \n",
      "50%              0.000000  \n",
      "75%              0.000000  \n",
      "max              1.000000  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature statistics:\")\n",
    "print(feature_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f282def-0996-4748-95ea-13da95897f0e",
   "metadata": {},
   "source": [
    "#### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dc0e7db-1502-4bda-9c72-ba56b56d4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ecb15-3250-4cfe-beda-9043504433ef",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "202813d5-6b98-4bfb-b057-9457987d790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = df['text'].tolist()\n",
    "X_tabular = scaled_features\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45cf2f4b-4b65-47b2-8412-d9767df0d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, X_tab_train, X_tab_test, y_train, y_test = train_test_split(\n",
    "    X_text, X_tabular, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab4085-4fe6-4f3b-a8ba-2d369edf63a8",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a32a8168-6803-4288-ba9e-a76a3af50f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fde80d50-37c0-4a91-9b99-63735d09a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_texts(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e2935-563f-4ce4-b1fd-e7338b0a7dc5",
   "metadata": {},
   "source": [
    "#### PYTORCH DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "393e0ebf-5848-4291-a4d0-28f041ef1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, texts, tabular_features, labels):\n",
    "        self.encodings = tokenize_texts(texts)\n",
    "        self.tabular = torch.tensor(tabular_features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['tabular'] = self.tabular[idx]\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ad4bb2-b9c1-4bd2-b4c6-f0ec1d3075c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HybridDataset(X_text_train, X_tab_train, y_train)\n",
    "test_dataset = HybridDataset(X_text_test, X_tab_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6d95ff7-c4f1-4eab-9095-3bba1bd01aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35400"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c2163b3-9652-4851-bc4b-1acae279d793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8851"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d38fd097-ebc0-4b17-b20a-81b93478d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9a7f1-a194-4039-95fa-9d4a76c11b5e",
   "metadata": {},
   "source": [
    "#### Hybrid Model (BERT + Tabular Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63167943-83b7-4b6e-9f80-12d77b1d2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTWithTabular(nn.Module):\n",
    "    def __init__(self, tabular_dim):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.tabular_fc = nn.Linear(tabular_dim, 64)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + 64, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, tabular, **kwargs):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        tab_feats = torch.relu(self.tabular_fc(tabular))\n",
    "        fused = torch.cat((pooled_output, tab_feats), dim=1)\n",
    "        fused = self.dropout(fused)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4fa08-cad9-4989-b55e-f101c897d714",
   "metadata": {},
   "source": [
    "#### training and model SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8efeaf25-30ea-4080-b24d-921d6079d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd484872-a901-4afc-b335-9e604e4a400d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f57b176-1433-4a3c-96ba-262c5487aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTWithTabular(tabular_dim=X_tabular.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9746a205-3643-44ec-b28c-bfd88207462b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTWithTabular(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (tabular_fc): Linear(in_features=23, out_features=64, bias=True)\n",
       "  (classifier): Linear(in_features=832, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dc80434-8d96-4f75-9b17-be7940dcb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9cee005-2067-41a4-b126-6d299bab1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f355f-66f7-46a0-ab6c-c40ab9beee71",
   "metadata": {},
   "source": [
    "#### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14ee1149-871a-4200-88f3-9bcb7ae3a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_accuracies = [], [], []\n",
    "best_val_loss = float('inf')\n",
    "patience, counter = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c535d86-f472-40cb-b6fd-0afa06e4e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader, start=1):\n",
    "        print(f\"[Train] Step {step}/{len(train_loader)}\")\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        tabular = batch['tabular'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, tabular)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be6764ff-59c9-468b-bb62-cecc71d7f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(test_loader, start=1):\n",
    "            print(f\"[Eval] Step {step}/{len(test_loader)}\")\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            tabular = batch['tabular'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, tabular)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    return avg_loss, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f743ce-bac3-47c2-8daa-6f25dab294c7",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42a44bc9-2011-4664-b2dc-a84d18c595cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Device: cpu\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "num_epochs = 3\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "counter = 0\n",
    "\n",
    "print(\"-\" * 100)\n",
    "print(f\"Device: {device}\")\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f910e-cac8-4e6b-acf1-69609a095f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "[Train] Step 1/277\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    # eval on validation set\n",
    "    val_loss, val_preds, val_labels = evaluate(model, test_loader, loss_fn, device)\n",
    "    \n",
    "    # validation accuracy\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    \n",
    "    # metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # epoch results\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # early-stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc\n",
    "        }, \"best_model.pt\")\n",
    "        print(f\"  New best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"  No improvement ({counter}/{patience})\")\n",
    "        \n",
    "        if counter >= patience:\n",
    "            print(\"  Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86ce7d-36fc-41ba-abb4-e528f276c1b7",
   "metadata": {},
   "source": [
    "#### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844bde4-21ac-4160-908b-1392ac4bf49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading best model for final evaluation\n",
    "checkpoint = torch.load(\"best_model.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Best model from epoch {checkpoint['epoch'] + 1} loaded (Val Loss: {checkpoint['val_loss']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51874c-a467-4def-bb97-54c948329d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "all_probas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46769d37-ef30-4b33-ab16-b99598eb7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        tabular = batch['tabular'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        logits = model(input_ids, attention_mask, tabular)\n",
    "        \n",
    "        # Get predictions and probabilities\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        probas = torch.softmax(logits, dim=1)[:, 1]  # Probability of positive class\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probas.extend(probas.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b03969e-ca37-48cb-8b48-df6b76dbabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# final metrics\n",
    "final_accuracy = accuracy_score(all_labels, all_preds)\n",
    "final_f1 = f1_score(all_labels, all_preds)\n",
    "final_auc = roc_auc_score(all_labels, all_probas)\n",
    "\n",
    "print(f\"final Accuracy = {final_accuracy:.4f}\")\n",
    "print(f\"final F1 Score = {final_f1:.4f}\")\n",
    "print(f\"final AUC-ROC = {final_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d670ee-5d66-40cb-8dfd-6938caccda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Ham', 'Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b77359-1c27-4727-b651-e79f8ff70eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Ham', 'Spam'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b0cb7-1501-489f-9e20-8eaffc772f20",
   "metadata": {},
   "source": [
    "#### Training/Validation Loss, Accuracy plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513bf83b-c92a-4dd5-81ee-11dbb79b4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "#1: train&val Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "#2: val Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, 'g-', label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "#3: train-val Loss \n",
    "plt.subplot(1, 3, 3)\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "plt.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "plt.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "plt.fill_between(epochs, train_losses, val_losses, alpha=0.2, color='gray')\n",
    "plt.title('Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e292e68-9b63-4b3a-bad3-008bff4a2310",
   "metadata": {},
   "source": [
    "#### TRAINING SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79da388-19ff-4bcf-a5be-f807a89c2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"epochs completed = {len(train_losses)}\")\n",
    "print(f\"best validation loss = {best_val_loss:.4f}\")\n",
    "print(f\"best validation accuracy = {max(val_accuracies):.4f}\")\n",
    "print(f\"final training loss = {train_losses[-1]:.4f}\")\n",
    "print(f\"final validation loss = {val_losses[-1]:.4f}\")\n",
    "print(f\"final validation accuracy = {val_accuracies[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e339e-a793-46ac-ae39-7687e497615b",
   "metadata": {},
   "source": [
    "#### SHAP INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a8b47-69d6-4739-a228-b5dc7a592f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import shap\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from shap.maskers import Text\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267e749-4dc0-4b97-b9ee-ded412a06ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== cleaning ==========\n",
    "def advanced_text_cleaning(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'(from:|to:|subject:|date:|reply-to:|message-id:).*?\\n', '', text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', ' URL_TOKEN ', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' EMAIL_TOKEN ', text)\n",
    "    text = re.sub(r'[\\+]?[1-9]?[0-9]{7,15}', ' PHONE_TOKEN ', text)\n",
    "    text = re.sub(r'[!]{3,}', ' MULTIPLE_EXCLAMATION ', text)\n",
    "    text = re.sub(r'[\\?]{3,}', ' MULTIPLE_QUESTION ', text)\n",
    "    text = re.sub(r'[$]{2,}', ' MULTIPLE_DOLLAR ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s!?$.]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# ========== Feature Engineering ==========\n",
    "def extract_email_features_row(text, url_count=0):\n",
    "    features = {\n",
    "        'char_count': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'sentence_count': text.count('.') + text.count('!') + text.count('?'),\n",
    "        'avg_word_length': len(text) / (len(text.split()) + 1e-5),\n",
    "        'exclamation_count': text.count('!'),\n",
    "        'question_count': text.count('?'),\n",
    "        'dollar_count': text.count('$'),\n",
    "        'capital_count': sum(1 for c in text if c.isupper()),\n",
    "        'capital_ratio': sum(1 for c in text if c.isupper()) / (len(text) + 1e-5),\n",
    "        'url_count': url_count,\n",
    "        'has_url': int(url_count > 0),\n",
    "        'has_attachment': int('attachment' in text.lower())\n",
    "    }\n",
    "    suspicious_words = ['urgent', 'immediate', 'act now', 'limited time', 'click here',\n",
    "                        'free', 'winner', 'prize', 'verify', 'confirm', 'suspended']\n",
    "    for word in suspicious_words:\n",
    "        features[f'contains_{word.replace(\" \", \"_\")}'] = int(word in text)\n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d7feb-a36c-433c-a3ba-ea803dcb41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Model (Only forward compatible for SHAP) ==========\n",
    "class BERTWithTabular(torch.nn.Module):\n",
    "    def __init__(self, tabular_dim):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.tabular_fc = torch.nn.Linear(tabular_dim, 64)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size + 64, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, tabular):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        tab_feats = torch.relu(self.tabular_fc(tabular))\n",
    "        fused = torch.cat((pooled_output, tab_feats), dim=1)\n",
    "        fused = self.dropout(fused)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f24af-f0f4-4c55-b50c-91b5b17de30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== loding Trained Model ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTWithTabular(tabular_dim=23).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1469f08-1b1e-42fe-91cd-75263d157ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"best_model.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1d769-f5b4-4c31-a748-49691b158b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SHAP Prediction Wrapper ==========\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "max_len = 256\n",
    "\n",
    "def predict_shap_raw(texts):\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    enc = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_len).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.bert(**enc).pooler_output\n",
    "    return output.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b6ba9-f12b-42a9-939d-f79248e62f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Inference Pipeline ==========\n",
    "def run_shap_inference(row, scaler, return_shap=True):\n",
    "    subject_clean = advanced_text_cleaning(row['subject'])\n",
    "    body_clean = advanced_text_cleaning(row['body'])\n",
    "    full_text = subject_clean + \" \" + body_clean\n",
    "    print(f\"[DEBUG] Text length: {len(full_text)}\")\n",
    "    print(f\"[DEBUG] Text preview: {full_text[:300]}\")\n",
    "    \n",
    "    # Tabular features\n",
    "    features_df = extract_email_features_row(full_text, row.get(\"urls\", 0))\n",
    "    tabular_tensor = torch.tensor(scaler.transform(features_df), dtype=torch.float32).to(device)\n",
    "\n",
    "    # Tokenization\n",
    "    enc = tokenizer([full_text], padding=True, truncation=True, return_tensors=\"pt\", max_length=max_len).to(device)\n",
    "\n",
    "    # Model prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(enc['input_ids'], enc['attention_mask'], tabular_tensor)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "        predicted_class = int(np.argmax(probs))\n",
    "        confidence = probs[predicted_class]\n",
    "\n",
    "    result = {\n",
    "        \"text\": full_text,\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"confidence\": confidence,\n",
    "        \"probabilities\": probs.tolist()\n",
    "    }\n",
    "\n",
    "    # SHAP explanation\n",
    "    if return_shap:\n",
    "        text_masker = Text(tokenizer=tokenizer)\n",
    "        explainer = shap.Explainer(predict_shap_raw, masker=text_masker)\n",
    "        shap_values = explainer([full_text])  # wrap in list\n",
    "        result[\"shap_values\"] = shap_values[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547ab2a-774a-4c52-9a3e-b14153e66cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/LOQ/Desktop/SpamAssasin.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/LOQ/Desktop/CEAS_08.csv\")\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.dropna(subset=['receiver', 'subject', 'body', 'label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7e577-9bfb-4a42-bf41-25bbf3f2096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject_clean'] = df['subject'].apply(advanced_text_cleaning)\n",
    "df['body_clean'] = df['body'].apply(advanced_text_cleaning)\n",
    "df['text'] = df['subject_clean'] + ' ' + df['body_clean']\n",
    "df = df[df['text'].str.len() > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785314b-2c4b-4ae3-8f5c-fcab8edc02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit scaler on all features\n",
    "feature_df = pd.concat([extract_email_features_row(t) for t in df['text']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4e02b-0903-4dcd-960e-f9df1be54a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c23e3-dee2-41c0-8679-3a58ae1b0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= pick one sample for testing/inference =========\n",
    "sample_row = df.iloc[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fa727-ad07-4ef0-adcf-457f927d7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fb541-7ea7-4dcf-9b66-6c6f3e395900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference + SHAP\n",
    "result = run_shap_inference(sample_row, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d4c73-b8f1-4580-88a2-1a2324ff3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= print & visualize =========\n",
    "print(f\"Prediction = {'Phishing' if result['predicted_class'] == 1 else 'Legitimate'}\")\n",
    "print(f\"Confidence = {result['confidence']:.3f}\")\n",
    "print(f\"Probabilities = {result['probabilities']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf9bae-a442-48f4-9782-8292dc7ad7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP-visualization\n",
    "shap.plots.text(result['shap_values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d17d8-31ae-4846-919c-fe2ff7683ba6",
   "metadata": {},
   "source": [
    "#### LIME INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d654ab-a98b-45cc-967a-d0f1ddfffaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0d8bb-c6e0-40d3-ae2f-ba75b817587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lime_inference(row, scaler, num_features=10):\n",
    "    subject_clean = advanced_text_cleaning(row['subject'])\n",
    "    body_clean = advanced_text_cleaning(row['body'])\n",
    "    full_text = subject_clean + \" \" + body_clean\n",
    "    base_features_df = extract_email_features_row(full_text, row.get(\"urls\", 0))\n",
    "    base_features_scaled = scaler.transform(base_features_df)\n",
    "    tabular_tensor_base = torch.tensor(base_features_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Define LIME prediction wrapper\n",
    "    def lime_predict(texts):\n",
    "        results = []\n",
    "        for txt in texts:\n",
    "            # Clean and extract tabular features for each LIME-perturbed sample\n",
    "            features_df = extract_email_features_row(txt)\n",
    "            features_scaled = scaler.transform(features_df)\n",
    "            tabular_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "            # Tokenize\n",
    "            enc = tokenizer([txt], padding=True, truncation=True, return_tensors=\"pt\", max_length=max_len).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(enc['input_ids'], enc['attention_mask'], tabular_tensor)\n",
    "                probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "                results.append(probs)\n",
    "\n",
    "        return np.array(results)\n",
    "\n",
    "    # explainer\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    explanation = explainer.explain_instance(full_text, lime_predict, num_features=num_features)\n",
    "\n",
    "    # prediction\n",
    "    pred_probs = lime_predict([full_text])[0]\n",
    "    predicted_class = int(np.argmax(pred_probs))\n",
    "    confidence = pred_probs[predicted_class]\n",
    "\n",
    "    result = {\n",
    "        \"text\": full_text,\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"confidence\": confidence,\n",
    "        \"probabilities\": pred_probs.tolist(),\n",
    "        \"lime_explanation\": explanation\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22c4c4-e1d9-4e12-854e-12f82e1abcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = df.iloc[20000]\n",
    "result_lime = run_lime_inference(sample_row, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d07ac-047b-4520-9dfd-fa8bbee0bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lime['lime_explanation'].show_in_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
